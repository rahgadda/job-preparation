# Large Language Model

## Overview

## Abbreviations
| Terminology         	| Description                                                                                                                                                                                                                                                                                                                                                                                                                                                           	|
|---------------------	|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	|
| Token               	| A unit of text that LLMs read, process, and generate, typically representing a word or a subword.                                                                                                                                                                                                                                                                                                                                                                     	|
| Prompt              	| The input text or query provided to an LLM to generate a coherent and relevant response.                                                                                                                                                                                                                                                                                                                                                                              	|
| Temperature         	| It is a hyperparameter that affects the randomness and diversity of the generated text.                                                                                                                                                                                                                                                                                                                                                                               	|
| Weights             	| It refer to the parameters or numerical values that the model learns during the training process.                                                                                                                                                                                                                                                                                                                                                                     	|
| Inference           	| The process of using a trained LLM to generate text in response to user inputs or queries.                                                                                                                                                                                                                                                                                                                                                                            	|
| Embedding           	| Refers to a technique in natural language processing and machine learning where words, phrases, images, or other entities are represented as dense, continuous vectors in a lower-dimensional space.                                                                                                                                                                                                                                                                  	|
| Prompt Engineering  	| The practice of designing effective prompts or inputs to elicit desired responses from an LLM.                                                                                                                                                                                                                                                                                                                                                                        	|
| Transfer Learning   	| A machine learning technique where knowledge gained from one task or domain (pre-training) is applied to another related task or domain (fine-tuning).                                                                                                                                                                                                                                                                                                                	|
| Foundational Models 	| Foundation models are AI models trained on huge amounts of unlabeled datasets that can be used to solve multiple downstream tasks.                                                                                                                                                                                                                                                                                                                                    	|
| Finetuned Models    	| This is an outcome of finetuning foundation model for a specific task.                                                                                                                                                                                                                                                                                                                                                                                                	|
| Fine-Tuning         	| The process of customizing a pre-trained LLM on a specific task or domain using a smaller dataset to make it more accurate and relevant.                                                                                                                                                                                                                                                                                                                              	|
| In-Context Learning 	| LLM continues learning or adapting during its interactions with users in real-time. This can involve updating the model's behavior, preferences, or biases based on the ongoing conversation or prompts it receives from users. In-context learning enables the LLM to provide more relevant and tailored responses over time.                                                                                                                                        	|
| Model Quantization  	| It is a technique to reduce the computational and memory costs of running inference by representing the weights and activations with low-precision data types like 8-bit integer (int8) instead of the usual 32-bit floating point (float32).<br>Reducing the number of bits means the resulting model requires less memory storage, consumes less energy (in theory), and operations like matrix multiplication can be performed much faster with integer arithmetic 	|
| Multi-modal LLM     	| An LLM that can process and generate text along with other types of media, such as images or audio.                                                                                                                                                                                                                                                                                                                                                                   	|