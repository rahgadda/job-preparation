# Large Language Model

## Overview

## Abbreviations
| Terminology         	| Description                                                                                                                                                                                                                                                                                                                    	|
|---------------------	|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	|
| Fine-Tuning         	| The process of customizing a pre-trained LLM on a specific task or domain using a smaller dataset to make it more accurate and relevant.                                                                                                                                                                                       	|
| In-Context Learning 	| LLM continues learning or adapting during its interactions with users in real-time. This can involve updating the model's behavior, preferences, or biases based on the ongoing conversation or prompts it receives from users. In-context learning enables the LLM to provide more relevant and tailored responses over time. 	|
| Inference           	| The process of using a trained LLM to generate text in response to user inputs or queries.                                                                                                                                                                                                                                     	|
| Weights             	| It refer to the parameters or numerical values that the model learns during the training process.                                                                                                                                                                                                                              	|
| Token               	| A unit of text that LLMs read, process, and generate, typically representing a word or a subword.                                                                                                                                                                                                                              	|
| Prompt              	| The input text or query provided to an LLM to generate a coherent and relevant response.                                                                                                                                                                                                                                       	|
| Prompt Engineering  	| The practice of designing effective prompts or inputs to elicit desired responses from an LLM.                                                                                                                                                                                                                                 	|
| Multi-modal LLM     	| An LLM that can process and generate text along with other types of media, such as images or audio.                                                                                                                                                                                                                            	|
| Transfer Learning   	| A machine learning technique where knowledge gained from one task or domain (pre-training) is applied to another related task or domain (fine-tuning).                                                                                                                                                                         	|